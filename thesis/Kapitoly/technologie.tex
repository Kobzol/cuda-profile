Tato kapitola popisuje technologie, knihovny a~principy použité při tvorbě profilovacího nástroje. Nejprve je popsán překladač LLVM, poté platforma pro výpočty na grafických kartách CUDA a~následně metody používané pro profilování aplikací.

\subsection{LLVM}
\emph{LLVM} je sada knihoven, které spolu tvoří infrastrukturu pro tvorbu překladačů a~programovacích jazyků~\cite{llvm}. Původně bylo LLVM vyvinuto jako open-source, rozšiřitelný a~modulární překladač pro jazyky \emph{C} a~\emph{C++}, který měl tvořil alternativu k~monolitickému překladači GCC. Později se z~něj stala univerzální platforma pro optimalizaci, analýzu, instrumentaci a~generování programů. Poskytuje funkcionalitu od zpracování zdrojového kódu až po vygenerování výsledných spustitelných souborů. LLVM se skládá ze sady frontendů, backendů a~virtuální instrukční sady nazvané LLVM IR.
\subsubsection*{Frontend}
Frontend je nástroj pro zpracování programu ve formě programovacího jazyka. Je zodpovědný za kontrolu (a~někdy i~automatickou opravu) syntaktických a~sémantických chyb v~kódu. Je naimplementován buď jako služba, kterou lze využít v~integrovaných programovacích prostředích anebo přímo jako součást překladače. Frontend nejprve provádí lexikální analýzu kódu a~následně z~něj vybuduje abstraktní syntaktický strom, nad kterým lze provádět analýzy. Poté z~tohoto stromu vygeneruje instrukce ve virtuální instrukční sadě LLVM IR. Každá z~těchto fází překladu je poskytována ve formě knihovny, což usnadňuje tvorbu frontendu pro nový programovací jazyk.
\subsubsection*{Backend}
Backend přijímá na vstupu LLVM IR instrukce, obvykle převzaté z~frontendu. Jeho úkolem je vygenerovat z~této virtuální instrukční sady spustitelný program určený pro konkrétní procesor, resp. instrukční sadu. Virtuální instrukce v~backendu procházejí sadou transformací. Nejprve dochází k~výběru instrukcí, kdy jsou jednotlivé IR instrukce nebo sady instrukcí transformovány do odpovídajících instrukcí pro cílovou architekturu. Následně je zvoleno co nejoptimálnější pořadí instrukcí pro maximální využití superskalárních architektur a~minimalizaci výpadků v~pipeline procesoru. Poté backend aplikuje běžné optimalizace (například peephole optimalizaci~\cite{peephole}) a~naalokuje registry pro instrukce. Ve finální části překladu dochází ke konverzi instrukcí buď do jazyka symbolických adres nebo přímo do strojových instrukcí pro zvolený procesor. Kromě přímého překladu do strojových instrukcí lze LLVM backend použít také pro dynamický překlad instrukcí za běhu programu (JIT překlad). Toho lze využít třeba pro optimalizaci kódu, jehož optimální vlastnosti nejsou v~době překladu známé, nebo pro emulaci chybějících hardwarových funkcí grafických akcelerátorů. Stejně jako u~frontendu poskytuje LLVM sadu rozhraní pro zjednodušení tvorby backendu pro novou instrukční sadu.
\subsubsection*{LLVM IR}
LLVM IR je instrukční sada pro virtuální procesor, takže není závislá na konkrétní hardwarové architektuře. Její instrukce jsou vždy v~tzv. SSA formě~\cite{ssa1, ssa2}, u~které je zaručeno, že do každé proměnné je zapsána hodnota právě jednou. Tato forma je běžně používána pro reprezentaci imperativních programovacích jazyků, protože usnadňuje analýzu programu a~aplikování optimalizací. LLVM poskytuje rozhraní pro optimalizaci, analýzu a~modifikaci IR instrukcí ve formě tzv. průchodů.
Průchod je funkce, která na vstupu přijímá IR modul, který může libovolně upravit a~poté jej vrátí k~dalšímu zpracování. IR modul obsahuje deklarace a~definice funkcí, globálních proměnných a~datových typů, ladící údaje a~údaje o~architektuře, pro kterou je modul určen. Při překladu jazyka C modul přibližně odpovídá jednotce překladu, obvykle tedy jednomu souboru s~implementací, který je překládán do formy objektového souboru. LLVM při překladu IR moduly postupně předává průchodům, které si lze navolit. LLVM obsahuje velké množství vestavěných průchodů, které jsou vždy zaměřené na jednu konkrétní věc z~oblasti analýzy (počítání instrukcí, sestavení grafu volání funkcí, analýza překrytí ukazatelů) nebo transformace (eliminace nedosažitelného kódu, propagace konstant, rozbalování cyklů) kódu. Při použití nejagresivnější optimalizace (-O3) pro překlad C/C++ programů se v~LLVM používá několik desítek těchto průchodů pro optimalizaci kódu. Lze také jednoduše vytvořit vlastní průchody, čehož bylo využito pro tvorbu profilovacího nástroje v~této práci.

Každý typ IR instrukce je v~kódu reprezentován třídou. Existují tak třídy pro instrukci načtení hodnoty z~paměti, sečtení dvou čísel nebo paměťové bariéry. Vzhledem k~tomu, kolik různých architektur a~programovacích jazyků LLVM podporuje, jsou jednotlivé třídy značně obsáhlé a~obecné. Třídy instrukcí tvoří hierarchii s~jedním společným předkem, třídou \texttt{Value}. Kromě instrukcí z~této třídy dědí i~hodnoty nacházející se v~kódu, například čísla nebo ukazatele. Všechny prvky vyskytující se v~IR tak lze reprezentovat tímto abstraktním rozhraním. To umožňuje zpracovávat jednotlivé instrukce a~hodnoty polymorfně, což velmi usnadňuje psaní nástrojů a~průchodů, které s~IR pracují. Pro některé účely je však nutné zjistit konkrétní typ daného objektu. Kvůli toho LLVM obsahuje vlastní dynamický typový systém, který je alternativou k~standardnímu systému C++ RTTI a~umožňuje za běhu aplikace zjišťovat typ objektů.
Instrukce jsou uspořádány do tzv. základních bloků (basic block), což je sekvence instrukcí bez větvení, s~právě jedním vstupním a~výstupním bodem. Toto logické uspořádání usnadňuje analýzu instrukcí, protože v~rámci jednoho bloku je zaručeno, že nedojde ke skoku mimo daný blok. Funkce jsou poté tvořeny skupinami těchto základních bloků. LLVM nabízí rozhraní pro procházení i~modifikaci všech výskytů dané instrukce nebo hodnoty v~rámci bloku či funkce, což usnadňuje modifikaci a~instrumentaci kódu.

Komponenty LLVM jsou modulární a~je snadné je použít jako knihovnu v~jiném programu. Pro vytvoření nového programovacího jazyka tak stačí napsat frontend pro zpracování syntaxe a~veškeré optimalizace a~generování kódu pro různé architektury poskytne LLVM bez nutnosti jakékoliv další práce. Stejně tak pokud vznikne nová hardwarová architektura, stačí pro ni vytvořit backend a~poté lze pro ni psát aplikace v~libovolném programovacím jazyce, který LLVM podporuje. Toto mimo jiné velmi urychluje experimenty s~vývojem nových programovacích jazyků, umožňuje vytvářet nástroje pro automatickou analýzu zdrojového i~strojového kódu a~jednoduše testovat nové optimalizace.
LLVM podporuje velké množství programovacích jazyků (například C, C++, Rust, Swift, D, C\#, Haskell, Java, Kotlin, Python) i~architektur (například ARM, MIPS, PTX, PowerPC, SPARC, x86, x64). Nejvíce vyvíjeným frontendem je state-of-the-art překladač jazyků C a~C++ \emph{Clang}, který je svou funkcionalitou srovnatelný s~běžně používaným překladačem \emph{GCC}. Mimo jiné podporuje i~překlad programů napsaných pro platformu CUDA.

\subsection{CUDA}
Grafické karty byly původně určené výhradně pro hardwarovou akceleraci 3D scén (hlavně ve videohrách a~modelovacích nástrojích). Díky své architektuře využívající velké množství výpočetních jader však začaly být brzy využívány také pro obecné výpočetní aplikace (například fyzikální, chemické, biologické či mechanické simulace), kde jejich použití mohlo významně zlepšit výkon programů. Grafické karty ovšem uměly řešit pouze problémy v~doméně počítačové grafiky, jiné výpočty tedy musely být převedeny do jazyka trojúhelníků a~textur. Tento způsob programování byl náročný a~neumožňoval naplno využít potenciál grafických akcelerátorů. Z~tohoto důvodu přišla v~roce 2007 společnost Nvidia s~platformou \emph{CUDA}~\cite{cuda}, která umožňuje efektivně provádět obecné výpočty na grafických kartách této společnosti. CUDA se skládá z~hardwarové architektury GPU, rozšíření jazyka C, které je použito k~psaní kódu pro GPU a~také ze sady knihoven mj. pro lineární algebru, zpracování signálů a~strojové učení, které jsou ručně optimalizovány pro efektivní využití dané architektury. CUDA byla jedním z~prvních rozhraní pro tzv. GPGPU\footnote{Obecné výpočty na grafických akcelerátorech}, díky rozšíření známého jazyka C je velmi jednoduché ji použít a~Nvidia jí poskytuje stálou podporu. V~roce 2009 vznikl otevřený standard OpenCL, který je narozdíl od platformy CUDA kompatibilní i~s~klasickými procesory a~grafickými kartami od jiných společností, než je Nvidia. Jeho vývoj je však pomalejší nutnosti udržovat kompatibilitu mezi všemi podporovanými platformami.

CUDA akcelerátory mohou spouštět až tisíce vláken, která provádí výpočty paralelně. Jednotlivá vlákna jsou organizována do trojrozměrných skupin (tzv. bloků). Ty jsou dále seskupeny do trojrozměrné mřížky~\cite{cudacguide}. Každé vlákno tak tvoří pomyslný bod v~šestirozměrném prostoru. Ukázku výpočetní mřížky si lze prohlédnout na obrázku \ref{fig:cudagrid}. Výpočet na grafické kartě je spouštěn pomocí funkcí, které se označují jako kernely. Při spuštění kernelu je nutné určit, jaké rozměry bude mít výpočetní mřížka a~bloky vláken. Toto rozdělení je užitečné při mapování výpočtu na dvourozměrné a~trojrozměrné úlohy, není ale nutné jej využívat. Vlákna mají při běhu k~dispozici informaci o~jejich pozici ve výpočetní mřížce, což lze použít například k~indexování do pole, textury, matice nebo jiné vícerozměrné datové struktury. Instrukce programu jsou vždy vykonávány v~tzv. warpech, což jsou skupiny 32 jader, které jsou vždy součástí jednoho bloku. Celý warp vždy vykonává stejnou instrukci nad různými daty, což lze chápat jako obdobu vektorových instrukcí na CPU. Tento způsob vykonávání kódu je označován jako SIMT\footnote{Single instruction, multiple threads}. Pokud GPU kód obsahuje podmínky, které rozdělí programový čítač warpu v~závislosti na datech, tak dojde k~tzv. divergenci warpu. Obě dvě větve podmínky jsou poté postupně vykonány celým warpem. Vlákna, která provádí větev, která pro ně není splněna, jsou označovány jako neaktivní. Efekt instrukcí provedených těmito vlákny je anulován pomocí vymaskování registrů. Takto desynchronizovaný warp samozřejmě není tak efektivní, jako když se provádí stejná instrukce všemi vlákny, je tedy žádoucí divergenci v~kódu minimalizovat. Warpy jsou prováděny na multiprocesorech (streaming multiprocessor) grafické karty. Ty obsahují plánovače warpů, které plánují vykonávání warpů podle vytížení procesoru a~paměťových závislostí. Nejnovější generace CUDA karet Volta umožňuje plánovat provádění instrukcí na úrovni jednotlivých vláken\footnote{ITS - independent thread scheduling}, ne celých warpů, což zmírňuje problém divergence warpů.

\InsertFigureSource{cudagrid}{0.5\textwidth}{Výpočetní mřížka CUDA vláken}{fig:cudagrid}{Nvidia Corporation~\cite{cudacguide}}

Grafické akcelerátory mají svou vlastní operační paměť, obvykle je tedy nutné zkopírovat data z~CPU na GPU před výpočtem a~poté zase zkopírovat výsledek zpátky v~opačném směru. Tento proces často tvoří úzké hrdlo aplikací, novější generace karet proto umožňují překrývat výpočet s~kopírováním dat nebo přímo přistupovat k~paměti procesoru z~grafické karty. V~paměti procesoru jsou data namapována do virtuálního adresního prostoru po jednotlivých stránkách. Při přesunu dat na GPU přes sběrnici PCI by tak mohlo dojít ke stránkovací chybě (page fault), například pokud je daná stránka odložena ve swapu na disku nebo pokud k~ní zatím nebylo přistoupeno. Proto dochází před samotným kopírováním přesun dat do tzv. page-locked (pinned) paměti, ve které k~tomuto dojít nemůže a~grafická karta tak může použít mechanismus přímého přístupu k~paměti (DMA) a~zkopírovat data bez asistence procesoru. Novější verze CUDY se snaží minimalizovat rozdíl mezi prací s~CPU a~GPU pamětí a~usnadnit tak programátorům práci. To umožňuje mechanismus Unified Virtual Addressing, který u~64-bitových aplikací sjednocuje paměť CPU a~GPU do jednoho společného virtuálního adresního prostoru. Díky tomu lze přistupovat k~paměti procesoru přímo z~grafické karty bez nutnosti speciální alokace dat (tyto přístupy ale samozřejmě mají kvůli nutnosti přenosu dat přes PCI sběrnici velkou odezvu). Tento koncept byl dále rozšířen pomocí Unified Memory, která automaticky migruje stránky mezi procesorem a~grafickou kartou a~zefektivňuje tak práci se sjednoceným adresním prostorem. Stejnou datovou strukturu tak lze používat na CPU i~GPU a~navíc při přístupu z~grafické karty budou data přesunuty do její paměti, což značně urychlí odezvu následujících přístupů.

CUDA zařízení mohou přistupovat k~1, 2, 4 nebo 8 bytům paměti v~rámci jedné instrukce. Adresy přístupů musí být zarovnané pro danou velikost přístupu, protože CUDA nepodporuje nezarovnané paměťové přístupy. Efektivita přístupů se odvíjí od toho, k~jakému typu paměti je přistupováno a~jaký vzor přístupu je použit. Níže následuje přehled jednotlivých typů paměti (resp. pohledů na paměť) CUDA akcelerátorů.
\begin{description}
    \item[Globální paměť] je hlavní paměť grafické karty, která má řádově jednotky GiB a~přístup do ní je relativně pomalý. Globální přístupy z~jednotlivých vláken v~rámci warpu jsou seskupeny pomocí transakcí, kdy je načteno 32, 64 nebo 128 bytů (podle velikosti řádky cache). Je výhodné načítat paměť z~po sobě jdoucích adres, aby těchto transakcí vznikalo co nejméně. Zároveň je vhodné, aby byly přístupy zarovnané na úroveň řádků cache (obvykle 128 bytů pro L1 a~32 bytů pro L2 cache). I~kdyby totiž vlákna přistupovala k~paměti sekvenčně, pokud bude rozsah paměti zasahovat do dvou řádků cache, budou vytvořeny dvě paměťové transakce. Na novějších CUDA architekturách jsou hodnoty načítané z~globální paměti udržovány pouze v~L2 cache~\cite{cudacguide}, u~starších verzí se ukládaly i~do L1 cache.
    \item[Lokální paměť] je používána pro velké lokální proměnné a~pole, pro které už nestačí velikost registrů. Data lokální paměťi jsou umístěna v~globální paměti (používá se pro ně ale rozdílná cache strategie), můžou tedy mít také značnou odezvu a~malou průchodnost.
    \item[Sdílená paměť] je rychlá a~malá paměť umístěná blízko k~výpočetním jádrům na čipu multiprocesoru. Tato paměť je sdílená v~rámci jednoho výpočetního bloku. Její velikost se pohybuje v~desítkách KiB pro každý blok. Paměťové přístupy k~sdílené paměti jsou prováděny pomocí paměťových modulů (memory bank), které jsou rozděleny po 4 bytech a~zpravidla je jich stejně jako vláken ve warpu, tedy 32. Modul, který bude použit pro paměťový přístup, je určen podle adresy, ke které se přistupuje. Pokud při paměťovém přístupu každé vlákno použije jiný modul, proběhnou všechny přístupy paralelně. Pokud ale dojde k~současnému přístupu více vláken pomocí stejného modulu, dojde ke konfliktu (tzv. bank conflict), což způsobí serializaci přístupů a~tedy i~zpomalení paměťové operace.
    \item[Texturovací paměť] je speciální cache nad globální pamětí, která je optimalizována pro 2D prostorové přístupy, čehož bývá často využíváno právě u~práci s~grafickými texturami. Tato paměť je pouze pro čtení.
    \item[Konstantní paměť] je také cache nad globální pamětí, která je optimalizována pro čtení malého počtu konstantních dat.
    \item[Registry] slouží ke stejnému účelu jako u~procesoru, tj. k~uchování malého množství pracovních dat, které jsou často využívány a~je k~nim poskytován velmi rychlý přístup. Jednotlivé bloky na CUDA zařízeních zpravidla obsahují tisíce registrů, které jsou sdíleny mezi aktivními vlákny.
\end{description}

Pro efektivní přístupy do paměti na grafické kartě je důležité, aby byly přístupy zarovnané a~ideálně blízko v~paměti u~sebe. Pokud dvě vlákna načítají data z~dvou po sobě jdoucích adres, tak může dojít ke sloučení těchto přístupů do jedné efektivní paměťové transakce. Pokud dvě vlákna načítají data z~dvou vzdálených míst ve (virtuální) paměti, tak musí transakce vzniknout dvě. Z~tohoto důvodu se může vyplatit používat pro kernely jinou reprezentaci dat než pro CPU. Problém efektivity přístupu do paměti může nastat například u~polí objektů (array of structures), které jsou běžné v~objektově orientovaných jazycích. Kernely často prochází všechny objekty v~poli, ale modifikují nebo čtou pouze několik vybraných atributů. V~této situaci dochází k~tomu, že i~když čteme z~paměti sekvenčně, tak jednotlivé hodnoty jsou v~paměti relativně daleko, protože mezi nimi leží všechny ostatní atributy daného objektu. Tento problém nenastává pouze u~grafických akcelerátorů, také u~CPU, protože při přednačítání (prefetch) do cache se zbytečně načítají atributy, které nejsou využity. Pro vyřešení tohoto problému lze pole struktur převést na tzv. strukturu polí (structure of arrays). Při tomto převodu je pro každý atribut objektu vytvořeno samostatné pole, které umožňuje přistupovat k~danému atributu sekvenčně v~paměti. Pokud tak bude kernel číst pouze jeden atribut objektu, tak bude přístup k~němu efektivní. Obdobný princip je například řádkové versus sloupcové uložení matic, vektorů či tabulek databáze. Detaily toho, jak vlákna do paměti přistupují, nemusí být zřejmé ze zdrojového kódu programu. Právě zobrazení těchto přístupů do paměti je tak jednou z~motivací pro tvorbu nástroje vyvíjeného v~této práci.

CUDA silně využívá paralelismu, musí tedy obsahovat mechanismy pro synchronizaci. Jednou z~nejpoužívanějších konstrukcí pro synchronizaci je instrukce \emph{syncthreads}, která slouží jako bariéra pro všechny warpy v~rámci bloku. Pokud vlákno provede tuto instrukci, tak je zablokováno, dokud ji neprovedou i~všechna ostatní vlákna v~bloku. Je tak nutné zajistit, aby tato instrukce byla provedena opravdu všemi vlákny bloku, jinak může dojít k~uzamčení (deadlock). Velmi užitečným synchronizačním mechanismem jsou také atomické instrukce. Ty fungují obdobně jako atomické instrukce procesoru - umožňují načíst, modifikovat a~zpětně zapsat několik bytů v~jedné atomické transakci, takže nemůže dojít k~přečtení nekonzistentních dat. Mezi podporované atomické operace patří např. inkrementace, sčítání, výběr maxima, výměna hodnoty a~CAS\footnote{Compare and swap je instrukce, která porovná hodnotu v~paměti s~referenční hodnotou a~pokud se rovnají, tak do paměti atomicky zapíše zadanou hodnotu. Často se používá pro implementaci ostatních atomických instrukcí.}. Původně byly tyto instrukce podporovány pouze pro 32bitová celá čísla, v~novějších verzích CUDY už je ale lze provádět i~na 64bitových číslech s~plovoucí řádovou čárkou a~to dokonce i~v~globální paměti.

CUDA programy jsou psány v~syntaktickém rozšíření jazyka C++, CUDA C. To poskytuje speciální syntaxi pro spouštění kernelů, pomocí které lze navolit, na kolika vláknech kernel poběží a~jakou strukturu bude mít výpočetní mřížka. Příklad spuštění kernelu si lze prohlédnout na výpisu \ref{code:kernellaunch}.

\begin{lstlisting}[language=C++,
caption=Spuštění kernelu,
label={code:kernellaunch},
inputencoding=utf8,
extendedchars=true,
literate={á}{{\'a}}1 {š}{{\v{s}}}1 {ě}{{\v{e}}}1 {í}{{\'i}}1 {ž}{{\v{z}}}1 {é}{{\'e}}1]
// spuštění kernelu s~16 bloky, v~každém bloku bude 32 vláken
addKernel<<<16, 32>>>(param1, param2);
\end{lstlisting}

Kernely musí být v~kódu označeny pomocí atributu $\_\_global\_\_$. Lze v~nich používat pouze funkce přeložené pro grafickou kartu, které jsou označeny atributem $\_\_device\_\_$ a~v~závislosti na použitém překladači nemohou využívat některé vlastnosti C++ (např. výjimky nebo funkcionalitu z~nejnovějších C++ standardů). CUDA programy lze přeložit buď proprietárním překladačem \emph{nvcc} od Nvidie nebo překladačem Clang. Překladač nvcc sice stejně jako Clang vnitřně používá LLVM IR pro reprezentaci kódu, nicméně zdrojový kód tohoto překladače není zveřejněn a~jeho vnitřní funkcionalita není zdokumentována. Proto je obtížné jej využít k~automatizované modifikaci CUDA programů. Clang naproti tomu umožňuje využít celou LLVM infrastrukturu pro analýzu a~modifikaci CUDA kódu a~dovoluje používat nejnovější C++ standardy při psaní GPU kódu, nicméně nepodporuje zatím všechny CUDA funkce a~optimalizace dostupné v~nvcc.

Při překladu CUDA programů je překládán zvlášť kód pro CPU a~GPU. Kód pro procesor je přeložen klasickým způsobem do formy objektových souborů. GPU kód je přeložen do PTX, zpětně i~dopředně kompatibilní instrukční sady pro CUDA karty. V~kernelech je možné přímo používat PTX instrukce, což je ekvivalentní použití jazyka symbolických instrukcí (assembly) pro CPU v~C kódu. Při spuštění aplikace driver grafické karty přeloží PTX kód pro architekturu použité grafické karty. Tento JIT překlad samozřejmě prodlužuje dobu spuštění aplikace, proto lze také přímo při překladu programu kromě PTX vygenerovat i~kód pro zvolené architektury karet a~přiložit ho ke spustitelnému souboru. Tím vzniká tzv. fatbinary - spustitelný soubor obsahující kód pro více architektur nebo instrukčních sad. PTX je uložen ve formě dat v~objektovém souboru, který se poté klasickým způsobem přilinkuje ke zbytku aplikace. Od verze 5 CUDA podporuje tzv. separátní překlad GPU kódu, kdy se každý soubor s~kódem pro grafickou kartu přeloží do přemístitelného objektového souboru, který je poté přilinkován k~výsledné aplikaci. Bez separátního překladu musí být všechny proměnné a~funkce použité v~GPU kódu ve stejném souboru (resp. ve stejné jednotce překladu).

\subsection{Metody profilování}
Pro profilování aplikace je nutné získat data o~běhu aplikace, a~to ideálně tak, aby to samotný běh aplikace ovlivnilo co nejméně. Základními způsoby pro sběr těchto dat jsou vzorkování a~instrumentace.

\subsubsection{Vzorkování}
Při výkonnostním profilování se často používá vzorkování (tzv. \emph{sampling}). Jedná se o~statistiskou metodu, kdy se program v~pravidelných intervalech (například co 10 milisekund) přerušuje a~při každém přerušení se uloží informace o~jeho současném stavu (zásobník volaných funkcí, stav registrů). Poté lze zpětně analyzovat v~které funkci program strávil nejvíce času nebo které instrukce v~jednotlivých metodách trvaly nejdéle. Naměřené vzorky lze vizualizovat různými způsoby. Jednou z~možností jsou tzv. flame chart~\cite{flamegraph}, který zobrazuje zaznamenané zásobníkové rámce. Dalším způsobem vizualizace je tzv. call graph, pomocí kterého lze vidět, které funkce se navzájem volaly a~kolik času bylo v~jednotlivých funkcích stráveno. Více o~vzorkování a~grafech vzájemného volání se lze dozvědět v~\cite{gprof}.

Vzorkování má výhodu v~tom, že téměř neovlivňuje výkonnostní charakteristiky sledovaného programu a~není složité jej naimplementovat. Jedná se však o~stochastický vzorkovací proces, takže nelze zachytit veškeré důležité informace o~běhu programu. Z~tohoto důvodu není tato metoda vhodná pro zachycení paměťových přístupů. Vzorkování je používáno například programy VTune~\cite{vtune} nebo CodeXL~\cite{codexl}.

\subsubsection{Instrumentace}
Další z~možností, jak získat informace o~běhu aplikace, je instrumentace. Ta spočívá v~(obvykle automatizovaném) umístění kódu na vybraných místech programu (například v~prologu či epilogu funkce). Tento kód zaznamenává informace za běhu programu nebo chování programu sám modifikuje. Kromě profilování lze tuto techniku použít například k~analýze korektnosti programů~\cite{memcheck}. Výhoda instrumentace spočívá v~tom, že umožňuje zachytit veškeré výskyty sledovaných událostí, narozdíl od náhodného vzorkování. Nevýhodou je fakt, že pokud je instrumentační kód volán často a~provádí složité operace, tak může značně zpomalit provádění programu a~zároveň zkreslit naměřená data. Kdyby například instrumentace zaznamenávala informace o~každé provedené instrukce, tak cena instrumentace bude mnohonásobně vyšší než samotné provádění programu. Takto použitá instrumentace poté měří spíše dobu svého provádění než dobu provádění programu. Účelem profilovacího nástroje vyvíjeného v~této práci však není měřit dobu výpočtu programu, ale získat data o~přístupech. Pro zaznamenání paměťových přístupů je tento přístup nutný a~proto je také v~nástroji použit.

Instrumentaci lze rozdělit do dvou kategorií - statická a~dynamická. Dynamická instrumentace modifikuje kód programu až za jeho běhu a~provádí se tedy přímo na instrukcích programu. Výhoda dynamického přístupu je v~tom, že si vystačí se spustitelným souborem a~nevyžaduje pro instrumentaci překlad aplikace (což je užitečné hlavně v~případě, kdy není původní zdrojový kód k~dispozici). Nicméně je relativně obtížné ji naimplementovat. Kromě čtení a~generování instrukcí je nutné taky částečně duplikovat funkci překladače, protože naivní přidání nebo úprava instrukcí v~programu může způsobit jeho pád nebo nežádoucí změnu chování. Instrumentační nástroje obvykle nejprve převedou instrukce programu do abstraktního formátu, který umožňuje jednoduchou modifikaci. Jakmile se do kódu přidají potřebné instrumentační funkce, tak dojde k~zpětnému překladu na strojové instrukce tak, aby program zůstal validní.
Dynamickou instrumentaci využívá například Valgrind~\cite{valgrind} nebo Pin~\cite{pin}.

Statická instrumentace probíhá před spuštěním programu a~lze ji provádět na zdrojovém kódu, přechodné reprezentaci programu nebo už na výsledném spustitelném souboru s~instrukcemi. Rozdíly mezi těmito způsoby jsou hlavně v~tom, kolik informací o~původním programu dokáží získat a~zda pro instrumentaci vyžadují překlad programu. Níže následuje popis jednotlivých reprezentací spolu s~výhodami a~nevýhodami jejich instrumentace.

\subsubsection*{Instrumentace zdrojového kódu}
Zdrojový kód poskytuje vysokou úrovni abstrakce a~obsahuje veškeré informace o~zápisu programu. Díky tomu, že je reprezentován textem, tak pro velmi jednoduchou instrumentaci lze použít i~prosté regulární výrazy. Kvůli jeho vysoké abstrakci nicméně nelze instrumentací zachytit nízkoúrovňové detaily o~chování programu (např. jednotlivé přístupy do paměti nebo práci s~registry procesoru). Nevýhodou je také nutnost přeložit celý program po instrumentaci. Původní zdrojový kód musí být před instrumentací zálohován, aby nebyl znehodnocen (popřípadě je nutné upravit překlad programu tak, aby vytvářel spustitelný soubor z~již instrumentovaného zdrojového kódu).

\subsubsection*{Instrumentace přechodného formátu}
Přechodný formát je používán pro popis programu v~překladačích. Usnadňuje analýzu programu bez nutnosti starat se o~syntaxi konkrétního programovacího jazyka a~o~detaily cílové architektury. Obvykle je tvořen sadou instrukcí pro virtuální stroj, které jsou ve finální fázi překladu převedeny na strojové instrukce pro zvolenou instrukční sadu. Příkladem tohoto formátu je již zmíněný LLVM IR. Jelikož IR vzniká ze zdrojového kódu, obsahuje metadata s~kompletními informacemi o~programu, zároveň je ale na mnohem nižší úrovni abstrakce než zdrojový kód a~umožňuje tak analyzovat a~instrumentovat jednotlivé instrukce programu. Tvoří tak užitečný kompromis mezi instrumentací zdrojového kódu a~strojových instrukcí. Jeho nevýhodou je nutnost překladu programu při instrumentaci a~také absence univerzálního standardu (každý překladač má obvykle svůj vlastní formát). Překladače také nemusí poskytovat rozhraní pro instrumentaci svého IR formátu.

\subsubsection*{Instrumentace strojových instrukcí}
Strojové instrukce postrádají část informací z~původního zdrojového kódu, umožňují ale instrumentovat a~analyzovat veškeré detaily chování programu. Na rozdíl od předchozích způsobů reprezentace nevyžadují opětovný překlad programu po instrumentaci. Instrumentovat přímo instrukce je nicméně obtížné ze stejných důvodů jako u~dynamické instrumentace -- je třeba načíst instrukce do abstraktního formátu a~poté je převést zpátky do instrukcí procesoru pro zaručení korektnosti programu modifikovaného instrumentací.
